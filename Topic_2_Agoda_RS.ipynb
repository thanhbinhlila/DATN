{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3849d05",
   "metadata": {},
   "source": [
    "## 0. Init Environment, Timestamp & Branding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1fd516b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]\n",
      "Platform: Windows-10-10.0.19045-SP0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import platform \n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "import unicodedata\n",
    "import warnings\n",
    "\n",
    "from datetime import datetime\n",
    "from math import sqrt, log2\n",
    "from pathlib import Path\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"Platform:\", platform.platform())\n",
    "\n",
    "DATA_DIR = Path(\"./data/\")\n",
    "OUTPUT_DIR = Path(\"./output/\")\n",
    "PLOTS_DIR = OUTPUT_DIR / \"plots/\"\n",
    "MODELS_DIR = OUTPUT_DIR / \"models/\"\n",
    "LOGS_DIR = OUTPUT_DIR / \"logs/\"\n",
    "PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LOGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "random.seed(RANDOM_STATE); np.random.seed(RANDOM_STATE)\n",
    "TS = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "p_info     = DATA_DIR / \"hotel_info.csv\"\n",
    "p_comments = DATA_DIR / \"hotel_comments.csv\"\n",
    "p_teencode = DATA_DIR / \"teencode.txt\"\n",
    "p_stop     = DATA_DIR / \"vietnamese-stopwords.txt\"\n",
    "p_emoji    = DATA_DIR / \"emojicon.txt\"\n",
    "p_wrong    = DATA_DIR / \"wrong-word.txt\"\n",
    "p_envi     = DATA_DIR / \"english-vnmese.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63b6bd4",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f1356aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hotel_info: (740, 14) | hotel_comments: (80314, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>Hotel_ID</th>\n",
       "      <th>Hotel_Name</th>\n",
       "      <th>Hotel_Rank</th>\n",
       "      <th>Hotel_Address</th>\n",
       "      <th>Total_Score</th>\n",
       "      <th>Location</th>\n",
       "      <th>Cleanliness</th>\n",
       "      <th>Service</th>\n",
       "      <th>Facilities</th>\n",
       "      <th>Value_for_money</th>\n",
       "      <th>Comfort_and_room_quality</th>\n",
       "      <th>comments_count</th>\n",
       "      <th>Hotel_Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "      <td>Khách sạn Mường Thanh Luxury Nha Trang (Muong ...</td>\n",
       "      <td>5 sao trên 5</td>\n",
       "      <td>60 Trần Phú, Lộc Thọ, Nha Trang, Việt Nam</td>\n",
       "      <td>8,8</td>\n",
       "      <td>9,4</td>\n",
       "      <td>8,9</td>\n",
       "      <td>8,9</td>\n",
       "      <td>8,7</td>\n",
       "      <td>8,7</td>\n",
       "      <td>8,3</td>\n",
       "      <td>1269</td>\n",
       "      <td>Khách sạn Mường Thanh Luxury Nha Trang - Nơi l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1_2</td>\n",
       "      <td>ALPHA BIRD NHA TRANG</td>\n",
       "      <td>4 sao trên 5</td>\n",
       "      <td>51/19/37 Tue Tinh St, Loc Tho Ward, Nha Trang,...</td>\n",
       "      <td>7,7</td>\n",
       "      <td>7,8</td>\n",
       "      <td>7,6</td>\n",
       "      <td>8,1</td>\n",
       "      <td>7,5</td>\n",
       "      <td>8,1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>337</td>\n",
       "      <td>ALPHA BIRD NHA TRANG - Khách sạn 4.0 sao tại N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num Hotel_ID                                         Hotel_Name  \\\n",
       "0    1      1_1  Khách sạn Mường Thanh Luxury Nha Trang (Muong ...   \n",
       "1    2      1_2                               ALPHA BIRD NHA TRANG   \n",
       "\n",
       "     Hotel_Rank                                      Hotel_Address  \\\n",
       "0  5 sao trên 5          60 Trần Phú, Lộc Thọ, Nha Trang, Việt Nam   \n",
       "1  4 sao trên 5  51/19/37 Tue Tinh St, Loc Tho Ward, Nha Trang,...   \n",
       "\n",
       "  Total_Score Location Cleanliness Service Facilities Value_for_money  \\\n",
       "0         8,8      9,4         8,9     8,9        8,7             8,7   \n",
       "1         7,7      7,8         7,6     8,1        7,5             8,1   \n",
       "\n",
       "  Comfort_and_room_quality  comments_count  \\\n",
       "0                      8,3            1269   \n",
       "1                      NaN             337   \n",
       "\n",
       "                                   Hotel_Description  \n",
       "0  Khách sạn Mường Thanh Luxury Nha Trang - Nơi l...  \n",
       "1  ALPHA BIRD NHA TRANG - Khách sạn 4.0 sao tại N...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>Hotel ID</th>\n",
       "      <th>Reviewer ID</th>\n",
       "      <th>Reviewer Name</th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Group Name</th>\n",
       "      <th>Room Type</th>\n",
       "      <th>Stay Details</th>\n",
       "      <th>Score</th>\n",
       "      <th>Score Level</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Review Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "      <td>1_1_1</td>\n",
       "      <td>MARIKO</td>\n",
       "      <td>Nhật Bản</td>\n",
       "      <td>Cặp đôi</td>\n",
       "      <td>Phòng Deluxe 2 Giường đơn Nhìn ra Biển</td>\n",
       "      <td>Đã ở 3 đêm vào Tháng 7 năm 2023</td>\n",
       "      <td>10,0</td>\n",
       "      <td>Trên cả tuyệt vời</td>\n",
       "      <td>Cao nhất‼︎”</td>\n",
       "      <td>Tôi đã ở cùng chủ nhân trong 4 đêm. Nhân viên ...</td>\n",
       "      <td>Đã nhận xét vào 30 tháng 7 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1_1</td>\n",
       "      <td>1_1_2</td>\n",
       "      <td>Hong</td>\n",
       "      <td>Việt Nam</td>\n",
       "      <td>Đi công tác</td>\n",
       "      <td>Phòng Deluxe 2 Giường đơn Nhìn ra Biển</td>\n",
       "      <td>Đã ở 1 đêm vào Tháng 9 năm 2022</td>\n",
       "      <td>10,0</td>\n",
       "      <td>Trên cả tuyệt vời</td>\n",
       "      <td>Tháng 8”</td>\n",
       "      <td>Lựa chọn Mường Thanh vì giá cả phù hợp. Đặt On...</td>\n",
       "      <td>Đã nhận xét vào 05 tháng 9 2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num Hotel ID Reviewer ID Reviewer Name Nationality   Group Name  \\\n",
       "0    1      1_1       1_1_1        MARIKO    Nhật Bản      Cặp đôi   \n",
       "1    2      1_1       1_1_2          Hong    Việt Nam  Đi công tác   \n",
       "\n",
       "                                Room Type                     Stay Details  \\\n",
       "0  Phòng Deluxe 2 Giường đơn Nhìn ra Biển  Đã ở 3 đêm vào Tháng 7 năm 2023   \n",
       "1  Phòng Deluxe 2 Giường đơn Nhìn ra Biển  Đã ở 1 đêm vào Tháng 9 năm 2022   \n",
       "\n",
       "  Score        Score Level        Title  \\\n",
       "0  10,0  Trên cả tuyệt vời  Cao nhất‼︎”   \n",
       "1  10,0  Trên cả tuyệt vời     Tháng 8”   \n",
       "\n",
       "                                                Body  \\\n",
       "0  Tôi đã ở cùng chủ nhân trong 4 đêm. Nhân viên ...   \n",
       "1  Lựa chọn Mường Thanh vì giá cả phù hợp. Đặt On...   \n",
       "\n",
       "                       Review Date  \n",
       "0  Đã nhận xét vào 30 tháng 7 2023  \n",
       "1  Đã nhận xét vào 05 tháng 9 2022  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def read_csv_safely(path, **kwargs):\n",
    "    for enc in [\"utf-8\", \"utf-8-sig\", \"cp1258\", \"latin-1\"]:\n",
    "        try:\n",
    "            return pd.read_csv(path, encoding=enc, **kwargs)\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "    raise last_err\n",
    "\n",
    "def read_dict_txt(path, splitter=None):\n",
    "    if not path.exists():\n",
    "        return {}\n",
    "    d = {}\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line: \n",
    "                continue\n",
    "            if splitter and splitter in line:\n",
    "                k, v = line.split(splitter, 1)\n",
    "                d[k.strip()] = v.strip()\n",
    "            else:\n",
    "                d[line] = \"\"\n",
    "    return d\n",
    "\n",
    "hotel_info     = read_csv_safely(p_info)\n",
    "hotel_comments = read_csv_safely(p_comments)\n",
    "\n",
    "teencode_map = read_dict_txt(p_teencode, splitter=\"\\\\t\") or {}\n",
    "stopwords    = set(read_dict_txt(p_stop).keys())\n",
    "emoji_map    = read_dict_txt(p_emoji, splitter=\"\\\\t\") or {}\n",
    "wrong_map    = set(read_dict_txt(p_wrong).keys())\n",
    "en_vi_map    = read_dict_txt(p_envi, splitter=\"\\\\t\") or {}\n",
    "\n",
    "print(\"hotel_info:\", hotel_info.shape, \"| hotel_comments:\", hotel_comments.shape)\n",
    "display(hotel_info.head(2)); display(hotel_comments.head(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9597e1",
   "metadata": {},
   "source": [
    "## 2. Identify Key Columns & EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "977686e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOIN KEY (comments->info): Hotel ID\n",
      "ALS columns -> user: Reviewer Name | hotel: Hotel ID | rating: Score\n",
      "ID: Hotel_ID | NAME: Hotel_Name | JOIN: Hotel ID\n",
      "ALS columns -> user: Reviewer Name | hotel: Hotel ID | rating: Score\n"
     ]
    }
   ],
   "source": [
    "text_cols = [c for c in hotel_info.columns if re.search(r'(Hotel_Description)', c, re.I)]\n",
    "id_cols   = [c for c in hotel_info.columns if re.search(r'(Hotel_ID)', c, re.I)]\n",
    "name_cols = [c for c in hotel_info.columns if re.search(r'(Hotel_Name)', c, re.I)]\n",
    "HOTEL_ID_COL   = id_cols[0] if id_cols else hotel_info.columns[0]\n",
    "HOTEL_NAME_COL = name_cols[0] if name_cols else (hotel_info.columns[1] if hotel_info.shape[1] > 1 else HOTEL_ID_COL)\n",
    "\n",
    "join_key = None\n",
    "for c in [HOTEL_ID_COL, \"Hotel ID\"]:\n",
    "    if c in hotel_comments.columns:\n",
    "        join_key = c; break\n",
    "print(\"JOIN KEY (comments->info):\", join_key)\n",
    "\n",
    "possible_rating_cols = [c for c in hotel_comments.columns if re.search(r'(Score)', c, re.I)]\n",
    "user_cols = [c for c in hotel_comments.columns if re.search(r'(Reviewer Name)', c, re.I)]\n",
    "user_col = user_cols[0] if user_cols else None\n",
    "hotel_col = None\n",
    "for c in [join_key, HOTEL_ID_COL, \"Hotel_ID\"]:\n",
    "    if c and c in hotel_comments.columns:\n",
    "        hotel_col = c; break\n",
    "\n",
    "rating_col = None\n",
    "for c in possible_rating_cols + [\"Score\"]:\n",
    "    if c in hotel_comments.columns:\n",
    "        rating_col = c; break\n",
    "\n",
    "print(\"ALS columns -> user:\", user_col, \"| hotel:\", hotel_col, \"| rating:\", rating_col)\n",
    "\n",
    "print(\"ID:\", HOTEL_ID_COL, \"| NAME:\", HOTEL_NAME_COL, \"| JOIN:\", join_key)\n",
    "print(\"ALS columns -> user:\", user_col, \"| hotel:\", hotel_col, \"| rating:\", rating_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa116b1",
   "metadata": {},
   "source": [
    "## 3 Vietnamese Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc840266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus prepared: count      740.000000\n",
      "mean      1783.562162\n",
      "std       4602.001683\n",
      "min          1.000000\n",
      "25%         12.000000\n",
      "50%         72.000000\n",
      "75%       1014.250000\n",
      "max      33057.000000\n",
      "Name: _corpus, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def normalize_unicode(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    return unicodedata.normalize(\"NFC\", text)\n",
    "\n",
    "def replace_emojis(text: str) -> str:\n",
    "    for emo, meaning in emoji_map.items():\n",
    "        text = text.replace(emo, f\" {meaning} \")\n",
    "    return text\n",
    "\n",
    "def apply_teencode(text: str) -> str:\n",
    "    toks = text.split()\n",
    "    out = [teencode_map.get(tok, tok) for tok in toks]\n",
    "    return \" \".join(out)\n",
    "\n",
    "def clean_text_basic(text: str) -> str:\n",
    "    text = re.sub(r\"http\\\\S+|www\\\\S+\", \" \", text)\n",
    "    text = re.sub(r\"[\\\\w.-]+@[\\\\w.-]+\", \" \", text)\n",
    "    text = re.sub(r\"\\\\d+\", \" \", text)\n",
    "    text = re.sub(r\"[^\\\\w\\\\sáàảãạăằắẳẵặâầấẩẫậéèẻẽẹêềếểễệíìỉĩịóòỏõọôồốổỗộơờớởỡợúùủũụưừứửữựýỳỷỹỵđ]\", \" \", text, flags=re.I)\n",
    "    text = re.sub(r\"\\\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "def remove_wrong_tokens(text: str) -> str:\n",
    "    toks = [t for t in text.split() if t not in wrong_map]\n",
    "    return \" \".join(toks)\n",
    "\n",
    "def en_to_vi_single_tokens(text: str) -> str:\n",
    "    toks = text.split()\n",
    "    out = [en_vi_map.get(t.lower(), t) for t in toks]\n",
    "    return \" \".join(out)\n",
    "\n",
    "def remove_stopwords(text: str) -> str:\n",
    "    toks = [t for t in text.split() if t.lower() not in stopwords and len(t) > 1]\n",
    "    return \" \".join(toks)\n",
    "\n",
    "def preprocess_vi(text: str) -> str:\n",
    "    text = normalize_unicode(str(text).lower())\n",
    "    text = replace_emojis(text)\n",
    "    text = apply_teencode(text)\n",
    "    text = clean_text_basic(text)\n",
    "    text = remove_wrong_tokens(text)\n",
    "    text = en_to_vi_single_tokens(text)\n",
    "    text = remove_stopwords(text)\n",
    "    return text\n",
    "\n",
    "hotel_info[\"_text_info\"]  = (hotel_info[text_cols].astype(str).agg(\" \".join, axis=1) if text_cols else \"\")\n",
    "hotel_comments[\"_merged_text\"] = hotel_comments.select_dtypes(include=[\"object\"]).astype(str).agg(\" \".join, axis=1).map(preprocess_vi)\n",
    "bag_reviews = {}\n",
    "if join_key and join_key in hotel_comments.columns:\n",
    "    bag_reviews = hotel_comments.groupby(join_key)[\"_merged_text\"].apply(lambda s: \" \".join(s.values.tolist())).to_dict()\n",
    "hotel_info[\"_bag_reviews\"] = hotel_info[HOTEL_ID_COL].map(bag_reviews).fillna(\"\")\n",
    "hotel_info[\"_corpus\"] = (hotel_info[\"_text_info\"].fillna(\"\").map(preprocess_vi) + \" \" + hotel_info[\"_bag_reviews\"].fillna(\"\"))\n",
    "print(\"Corpus prepared:\", hotel_info[\"_corpus\"].str.len().describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554a65df",
   "metadata": {},
   "source": [
    "## 4. Content-Based: TF-IDF / Doc2Vec / SBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "732e4cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF demo:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotel_ID</th>\n",
       "      <th>Hotel_Name</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>21_8</td>\n",
       "      <td>Khách sạn Alana Nha Trang (Alana Nha Trang Bea...</td>\n",
       "      <td>0.932841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>4_16</td>\n",
       "      <td>Khách sạn Dqua (DQua Hotel)</td>\n",
       "      <td>0.925117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6_27</td>\n",
       "      <td>Vinpearl Beachfront Nha Trang</td>\n",
       "      <td>0.915213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1_8</td>\n",
       "      <td>Navada Beach Hotel</td>\n",
       "      <td>0.902252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>22_7</td>\n",
       "      <td>Khách Sạn và Spa Emerald Bay (Emerald Bay Hote...</td>\n",
       "      <td>0.889396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Hotel_ID                                         Hotel_Name  similarity\n",
       "233     21_8  Khách sạn Alana Nha Trang (Alana Nha Trang Bea...    0.932841\n",
       "623     4_16                        Khách sạn Dqua (DQua Hotel)    0.925117\n",
       "141     6_27                      Vinpearl Beachfront Nha Trang    0.915213\n",
       "7        1_8                                 Navada Beach Hotel    0.902252\n",
       "241     22_7  Khách Sạn và Spa Emerald Bay (Emerald Bay Hote...    0.889396"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec demo:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotel_ID</th>\n",
       "      <th>Hotel_Name</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>33_9</td>\n",
       "      <td>Căn hộ 42 m² 1 phòng ngủ, 1 phòng tắm riêng ở ...</td>\n",
       "      <td>0.435595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>3_10</td>\n",
       "      <td>Khách sạn Dendro Gold (Dendro Gold Hotel )</td>\n",
       "      <td>0.406185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>3_5</td>\n",
       "      <td>TTC Van Phong Bay Resort</td>\n",
       "      <td>0.372891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>15_27</td>\n",
       "      <td>Khách sạn Novotel Nha Trang (Novotel Nha Trang...</td>\n",
       "      <td>0.370652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>21_8</td>\n",
       "      <td>Khách sạn Alana Nha Trang (Alana Nha Trang Bea...</td>\n",
       "      <td>0.343720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Hotel_ID                                         Hotel_Name  similarity\n",
       "294     33_9  Căn hộ 42 m² 1 phòng ngủ, 1 phòng tắm riêng ở ...    0.435595\n",
       "69      3_10         Khách sạn Dendro Gold (Dendro Gold Hotel )    0.406185\n",
       "64       3_5                           TTC Van Phong Bay Resort    0.372891\n",
       "188    15_27  Khách sạn Novotel Nha Trang (Novotel Nha Trang...    0.370652\n",
       "233     21_8  Khách sạn Alana Nha Trang (Alana Nha Trang Bea...    0.343720"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBERT demo:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotel_ID</th>\n",
       "      <th>Hotel_Name</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1_15</td>\n",
       "      <td>Khách Sạn Erica Nha Trang (Erica Nha Trang Hotel)</td>\n",
       "      <td>0.994349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>13_8</td>\n",
       "      <td>DTX Hotel Nha Trang</td>\n",
       "      <td>0.993885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>15_27</td>\n",
       "      <td>Khách sạn Novotel Nha Trang (Novotel Nha Trang...</td>\n",
       "      <td>0.992314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2_5</td>\n",
       "      <td>Khách sạn Boutique Seasing (Seasing Boutique H...</td>\n",
       "      <td>0.991967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>3_19</td>\n",
       "      <td>Khách sạn Super OYO 598 Peony (Super OYO 598 P...</td>\n",
       "      <td>0.991938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Hotel_ID                                         Hotel_Name  similarity\n",
       "14      1_15  Khách Sạn Erica Nha Trang (Erica Nha Trang Hotel)    0.994349\n",
       "164     13_8                                DTX Hotel Nha Trang    0.993885\n",
       "188    15_27  Khách sạn Novotel Nha Trang (Novotel Nha Trang...    0.992314\n",
       "34       2_5  Khách sạn Boutique Seasing (Seasing Boutique H...    0.991967\n",
       "78      3_19  Khách sạn Super OYO 598 Peony (Super OYO 598 P...    0.991938"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=50000, ngram_range=(1,2), min_df=2)\n",
    "X_tfidf = tfidf.fit_transform(hotel_info[\"_corpus\"])\n",
    "COS_TFIDF = cosine_similarity(X_tfidf)\n",
    "\n",
    "# Doc2Vec\n",
    "D2V_EMB, COS_D2V = None, None\n",
    "try:\n",
    "    from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "    documents = [TaggedDocument(words=row.split(), tags=[str(hid)]) \n",
    "                 for row, hid in zip(hotel_info[\"_corpus\"].tolist(), hotel_info[HOTEL_ID_COL].astype(str).tolist())]\n",
    "    d2v = Doc2Vec(vector_size=128, window=5, min_count=2, workers=4, epochs=30, dm=1)\n",
    "    d2v.build_vocab(documents)\n",
    "    d2v.train(documents, total_examples=d2v.corpus_count, epochs=d2v.epochs)\n",
    "    D2V_EMB = np.vstack([d2v.infer_vector(doc.words) for doc in documents])\n",
    "    COS_D2V = cosine_similarity(D2V_EMB, D2V_EMB)\n",
    "except Exception as e:\n",
    "    print(\"Doc2Vec unavailable:\", repr(e))\n",
    "\n",
    "# SBERT\n",
    "SBERT_EMB, COS_SBERT = None, None\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    model_name = \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "    sbert_model = SentenceTransformer(model_name)\n",
    "    SBERT_EMB = sbert_model.encode(hotel_info[\"_corpus\"].tolist(), convert_to_numpy=True, show_progress_bar=False)\n",
    "    COS_SBERT = cosine_similarity(SBERT_EMB, SBERT_EMB)\n",
    "except Exception as e:\n",
    "    print(\"SBERT unavailable:\", repr(e))\n",
    "\n",
    "try:\n",
    "    if D2V_EMB is not None:\n",
    "        np.save(MODELS_DIR / \"d2v_emb.npy\", D2V_EMB)\n",
    "    if SBERT_EMB is not None:\n",
    "        np.save(MODELS_DIR / \"sbert_emb.npy\", SBERT_EMB)\n",
    "except Exception as e:\n",
    "    print(\"Skip saving emb:\", repr(e))\n",
    "\n",
    "def recommend_from_sim(seed_hotel_id, sim_matrix, topn=10):\n",
    "    if seed_hotel_id not in set(hotel_info[HOTEL_ID_COL]):\n",
    "        raise ValueError(\"Hotel ID not found\")\n",
    "    idx = hotel_info.index[hotel_info[HOTEL_ID_COL] == seed_hotel_id][0]\n",
    "    sims = sim_matrix[idx]\n",
    "    order = np.argsort(-sims)[:topn+1]\n",
    "    order = [i for i in order if i != idx][:topn]\n",
    "    out = hotel_info.iloc[order][[HOTEL_ID_COL, HOTEL_NAME_COL]].copy()\n",
    "    out[\"similarity\"] = sims[order]\n",
    "    return out\n",
    "\n",
    "if len(hotel_info) > 1:\n",
    "    demo_id = hotel_info.iloc[0][HOTEL_ID_COL]\n",
    "    print(\"TF-IDF demo:\"); display(recommend_from_sim(demo_id, COS_TFIDF, 5))\n",
    "    if COS_D2V is not None: \n",
    "        print(\"Doc2Vec demo:\"); display(recommend_from_sim(demo_id, COS_D2V, 5))\n",
    "    if COS_SBERT is not None:\n",
    "        print(\"SBERT demo:\"); display(recommend_from_sim(demo_id, COS_SBERT, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c6e28f",
   "metadata": {},
   "source": [
    "## 5. Collaborative Filtering (Spark ALS) — Grid Search RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26ebb320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of raw scoring that couldn’t be parsed:\n",
      "Series([], Name: Score, dtype: object)\n",
      "ALS dataframe shape: (80228, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewer Name</th>\n",
       "      <th>Hotel ID</th>\n",
       "      <th>__rating_clean</th>\n",
       "      <th>__userId</th>\n",
       "      <th>__itemId</th>\n",
       "      <th>__rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MARIKO</td>\n",
       "      <td>1_1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hong</td>\n",
       "      <td>1_1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Guai</td>\n",
       "      <td>1_1</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nghĩa</td>\n",
       "      <td>1_1</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Duc</td>\n",
       "      <td>1_1</td>\n",
       "      <td>9.2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Reviewer Name Hotel ID  __rating_clean  __userId  __itemId  __rating\n",
       "0        MARIKO      1_1            10.0         0         0      10.0\n",
       "1          Hong      1_1            10.0         1         0      10.0\n",
       "2          Guai      1_1             9.2         2         0       9.2\n",
       "3         Nghĩa      1_1             8.8         3         0       8.8\n",
       "4           Duc      1_1             9.2         4         0       9.2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert rating_col is not None, \"Score column not found.\"\n",
    "\n",
    "def normalize_rating(series: pd.Series) -> pd.Series:\n",
    "\n",
    "    s = series.astype(str).str.strip()\n",
    "    s = s.replace({\"\": np.nan, \"nan\": np.nan, \"None\": np.nan, \"N/A\": np.nan, \"na\": np.nan})\n",
    "    num = s.str.extract(r'([0-9]{1,3}(?:[.,][0-9]{1,2})?)', expand=False)\n",
    "    num = num.str.replace(r'(?<=\\d)\\.(?=\\d{3}(?:\\D|$))', '', regex=True)\n",
    "    num = num.str.replace(',', '.', regex=False)\n",
    "    out = pd.to_numeric(num, errors='coerce').clip(lower=0, upper=10)\n",
    "    return out\n",
    "\n",
    "hotel_comments['__rating_clean'] = normalize_rating(hotel_comments[rating_col])\n",
    "bad_mask = hotel_comments['__rating_clean'].isna() & hotel_comments[rating_col].notna()\n",
    "print(\"Example of raw scoring that couldn’t be parsed:\")\n",
    "print(hotel_comments.loc[bad_mask, rating_col].drop_duplicates().head(10))\n",
    "\n",
    "als_df = hotel_comments[[user_col, hotel_col, '__rating_clean']].dropna().copy()\n",
    "\n",
    "if not np.issubdtype(als_df[user_col].dtype, np.number):\n",
    "    als_df['__userId'] = pd.factorize(als_df[user_col])[0].astype('int32')\n",
    "else:\n",
    "    als_df['__userId'] = als_df[user_col].astype('int32')\n",
    "\n",
    "if not np.issubdtype(als_df[hotel_col].dtype, np.number):\n",
    "    als_df['__itemId'] = pd.factorize(als_df[hotel_col])[0].astype('int32')\n",
    "else:\n",
    "    als_df['__itemId'] = als_df[hotel_col].astype('int32')\n",
    "\n",
    "als_df['__rating'] = als_df['__rating_clean'].astype('float32')\n",
    "\n",
    "print(\"ALS dataframe shape:\", als_df.shape)\n",
    "als_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d286488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark ALS is unavailable: ModuleNotFoundError(\"No module named 'findspark'\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_24432\\4036806901.py\", line 9, in <module>\n",
      "    import findspark\n",
      "ModuleNotFoundError: No module named 'findspark'\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfindspark\u001b[39;00m\n\u001b[32m     10\u001b[39m     findspark.init()\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'findspark'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 111\u001b[39m\n\u001b[32m    109\u001b[39m traceback.print_exc()\n\u001b[32m    110\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSpark ALS is unavailable:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mrepr\u001b[39m(e))\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m \u001b[43msc\u001b[49m.stop()\n\u001b[32m    112\u001b[39m spark.stop()\n",
      "\u001b[31mNameError\u001b[39m: name 'sc' is not defined"
     ]
    }
   ],
   "source": [
    "als_search_result = {\"ok\": False, \"best\": None, \"trials\": []}\n",
    "BEST_ALS_MODEL = None\n",
    "\n",
    "if not (user_col and hotel_col and rating_col):\n",
    "    print(\"Insufficient columns to run ALS. Required: (user, hotel, score).\")\n",
    "else:\n",
    "    try:\n",
    "\n",
    "        import findspark\n",
    "        findspark.init()\n",
    "\n",
    "        from pyspark import SparkContext\n",
    "        from pyspark.sql import functions as F, types as T\n",
    "        from pyspark.sql import SparkSession\n",
    "        from pyspark.sql.functions import *\n",
    "\n",
    "        from pyspark.ml.recommendation import ALS\n",
    "        from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "        SparkContext.setSystemProperty('spark.hadoop.dfs.client.use.datanode.hostname', 'true')\n",
    "        sc = SparkContext(master=\"local\", appName=\"New Spark Context\")\n",
    "        sc.setLogLevel(\"ERROR\")\n",
    "\n",
    "        from pyspark.sql import SparkSession\n",
    "        spark = SparkSession(sc)\n",
    "        spark\n",
    "\n",
    "        pdf = als_df[['__userId','__itemId','__rating']].copy()\n",
    "        pdf['__userId'] = pdf['__userId'].astype('int64')\n",
    "        pdf['__itemId'] = pdf['__itemId'].astype('int64')\n",
    "        pdf['__rating'] = pdf['__rating'].astype('float64')\n",
    "\n",
    "        sdf = spark.createDataFrame(pdf) \\\n",
    "            .withColumnRenamed('__userId','userId') \\\n",
    "            .withColumnRenamed('__itemId','itemId') \\\n",
    "            .withColumnRenamed('__rating','rating') \\\n",
    "            .select(\n",
    "                F.col('userId').cast(T.IntegerType()),\n",
    "                F.col('itemId').cast(T.IntegerType()),\n",
    "                F.col('rating').cast(T.DoubleType())\n",
    "            )\n",
    "\n",
    "        print(\"Schema cho ALS:\")\n",
    "        sdf.printSchema()\n",
    "        sdf.show(5, truncate=False)\n",
    "\n",
    "        train, test = sdf.randomSplit([0.8, 0.2], seed=RANDOM_STATE)\n",
    "        evaluator = RegressionEvaluator(\n",
    "            metricName=\"rmse\",\n",
    "            labelCol=\"rating\",\n",
    "            predictionCol=\"prediction\"\n",
    "        )\n",
    "\n",
    "        param_grid = {\n",
    "            \"rank\": [10, 20, 40],\n",
    "            \"regParam\": [0.01, 0.05, 0.1],\n",
    "            \"maxIter\": [10, 15]\n",
    "        }\n",
    "\n",
    "        best = {\"rmse\": float(\"inf\"), \"params\": None, \"model\": None}\n",
    "        trial_id = 0\n",
    "\n",
    "        for r in param_grid[\"rank\"]:\n",
    "            for reg in param_grid[\"regParam\"]:\n",
    "                for it in param_grid[\"maxIter\"]:\n",
    "                    trial_id += 1\n",
    "                    als = ALS(\n",
    "                        maxIter=it,\n",
    "                        regParam=reg,\n",
    "                        rank=r,\n",
    "                        userCol=\"userId\",\n",
    "                        itemCol=\"itemId\",\n",
    "                        ratingCol=\"rating\",\n",
    "                        nonnegative=True,\n",
    "                        coldStartStrategy=\"drop\"\n",
    "                    )\n",
    "\n",
    "                    model = als.fit(train)\n",
    "                    preds = model.transform(test)\n",
    "\n",
    "                    preds = preds.filter(F.col(\"prediction\").isNotNull())\n",
    "\n",
    "                    print(f\"[DBG] trial={trial_id} schema prediction:\")\n",
    "                    preds.select(\"userId\",\"itemId\",\"rating\",\"prediction\").printSchema()\n",
    "\n",
    "                    rmse = evaluator.evaluate(preds)\n",
    "                    als_search_result[\"trials\"].append(\n",
    "                        {\"trial\": trial_id, \"rank\": r, \"regParam\": reg, \"maxIter\": it, \"rmse\": rmse}\n",
    "                    )\n",
    "                    print(f\"[Trial {trial_id}] rank={r} reg={reg} iter={it} -> RMSE={rmse:.4f}\")\n",
    "\n",
    "                    if rmse < best[\"rmse\"]:\n",
    "                        best = {\"rmse\": rmse, \"params\": {\"rank\": r, \"regParam\": reg, \"maxIter\": it}, \"model\": model}\n",
    "\n",
    "        als_search_result[\"ok\"] = True\n",
    "        als_search_result[\"best\"] = {\"rmse\": best[\"rmse\"], \"params\": best[\"params\"]}\n",
    "        BEST_ALS_MODEL = best[\"model\"]\n",
    "        print(\"\\nBest ALS:\", als_search_result[\"best\"])\n",
    "\n",
    "        BEST_ALS_MODEL.write().overwrite().save(str(MODELS_DIR / \"best_als_model\"))\n",
    "        pd.DataFrame(als_search_result[\"trials\"]).to_csv(\n",
    "            LOGS_DIR / f\"als_gridsearch_results_{TS}.csv\", index=False\n",
    "        )\n",
    "        sc.stop()\n",
    "        spark.stop()\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        print(\"Spark ALS is unavailable:\", repr(e))\n",
    "        sc.stop()\n",
    "        spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491fcaac",
   "metadata": {},
   "source": [
    "## 6. Evaluation + Bar Charts (PNG) + Markdown/PPTX Report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5082254",
   "metadata": {},
   "outputs": [],
   "source": [
    "import builtins\n",
    "try:\n",
    "    from pyspark.sql import functions as F\n",
    "    for _name in (\"col\", \"map\", \"filter\", \"min\", \"max\", \"sum\"):\n",
    "        if _name in globals():\n",
    "            try: del globals()[_name]\n",
    "            except Exception: pass\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "def _py_min(a, b): return builtins.min(a, b)\n",
    "\n",
    "N_SEEDS = 300\n",
    "MIN_REL  = 2\n",
    "K_LIST   = [5, 10, 20]\n",
    "\n",
    "if not (user_col and hotel_col):\n",
    "    raise RuntimeError(\"Missing user/hotel columns to create the Jaccard ground truth.\")\n",
    "df_pair = hotel_comments[[user_col, hotel_col]].dropna().drop_duplicates()\n",
    "try:\n",
    "    df_pair[hotel_col] = df_pair[hotel_col].astype(hotel_info[HOTEL_ID_COL].dtype)\n",
    "except Exception:\n",
    "    pass\n",
    "users_by_hotel = df_pair.groupby(hotel_col)[user_col].apply(set).to_dict()\n",
    "hotel_ids = hotel_info[HOTEL_ID_COL].tolist()\n",
    "\n",
    "def jaccard_list(hid, topn=1000):\n",
    "    u = users_by_hotel.get(hid, set())\n",
    "    if not u: return []\n",
    "    res = []\n",
    "    for other, u2 in users_by_hotel.items():\n",
    "        if other == hid: continue\n",
    "        inter = len(u & u2)\n",
    "        if inter == 0: continue\n",
    "        union = len(u | u2)\n",
    "        jac = inter / union if union else 0.0\n",
    "        if jac > 0: res.append((other, float(jac)))\n",
    "    res.sort(key=lambda x: x[1], reverse=True)\n",
    "    return res[:topn]\n",
    "\n",
    "candidates = [hid for hid in hotel_ids if len(jaccard_list(hid, 1000)) >= MIN_REL]\n",
    "if not candidates:\n",
    "    raise RuntimeError(\"No seeds meet the MIN_REL threshold for evaluation.\")\n",
    "\n",
    "k_seed = _py_min(N_SEEDS, len(candidates))\n",
    "seeds = random.sample(candidates, k_seed)\n",
    "\n",
    "def precision_at_k(recommended, relevant_set, k: int):\n",
    "    rec = list(recommended)[:int(k)]\n",
    "    rel = set(relevant_set)\n",
    "    hits = sum(1 for x in rec if x in rel)\n",
    "    return hits / builtins.max(int(k), 1)\n",
    "\n",
    "def apk(recommended, relevant_set, k: int):\n",
    "    rec = list(recommended)[:int(k)]\n",
    "    rel = set(relevant_set)\n",
    "    hits = 0\n",
    "    score = 0.0\n",
    "    for i, r in enumerate(rec, start=1):\n",
    "        if r in rel:\n",
    "            hits += 1\n",
    "            score += hits / i\n",
    "    return score / builtins.max(builtins.min(len(rel), int(k)), 1)\n",
    "\n",
    "from math import log2\n",
    "def ndcg_at_k_binary(recommended, relevant_set, k: int):\n",
    "    rec = list(recommended)[:int(k)]\n",
    "    rel = set(relevant_set)\n",
    "    def dcg(items):\n",
    "        s = 0.0\n",
    "        for i, it in enumerate(items, start=1):\n",
    "            s += (2.0**(1.0 if it in rel else 0.0) - 1.0) / log2(i + 1)\n",
    "        return s\n",
    "    dcg_val = dcg(rec)\n",
    "    ideal = dcg(list(rel))\n",
    "    return (dcg_val / ideal) if ideal > 0 else 0.0\n",
    "\n",
    "def ndcg_at_k_graded(recommended, gains_dict, k: int):\n",
    "    rec = list(recommended)[:int(k)]\n",
    "    gains = dict(gains_dict)\n",
    "    def dcg(items):\n",
    "        s = 0.0\n",
    "        for i, it in enumerate(items, start=1):\n",
    "            rel = gains.get(it, 0.0)\n",
    "            s += (2.0**rel - 1.0) / log2(i + 1)\n",
    "        return s\n",
    "    dcg_val = dcg(rec)\n",
    "    ideal_items = [it for it, g in sorted(gains.items(), key=lambda x: x[1], reverse=True)]\n",
    "    idcg = dcg(ideal_items[:int(k)])\n",
    "    return (dcg_val / idcg) if idcg > 0 else 0.0\n",
    "\n",
    "def topk_from_sim(sim_matrix, idx, topn):\n",
    "    sims = sim_matrix[idx]\n",
    "    order = np.argsort(-sims)[:topn+1]\n",
    "    order = [i for i in order if i != idx][:topn]\n",
    "    return hotel_info.iloc[order][HOTEL_ID_COL].tolist()\n",
    "\n",
    "def eval_method(name, sim_matrix, topn=200):\n",
    "    rows = []\n",
    "    for hid in seeds:\n",
    "        idx = id_to_idx.get(hid, None)\n",
    "        if idx is None: \n",
    "            continue\n",
    "        recs = topk_from_sim(sim_matrix, idx, topn=topn)\n",
    "        jlist = jaccard_list(hid, topn=1000)\n",
    "        rel_set = set([h for h, g in jlist])\n",
    "        gains   = {h: g for h, g in jlist}\n",
    "        for K in K_LIST:\n",
    "            rows.append({\n",
    "                \"method\": name, \"K\": K, \"seed_hotel\": hid,\n",
    "                \"precision\": precision_at_k(recs, rel_set, K),\n",
    "                \"map\":       apk(recs, rel_set, K),\n",
    "                \"ndcg_bin\":  ndcg_at_k_binary(recs, rel_set, K),\n",
    "                \"ndcg_grd\":  ndcg_at_k_graded(recs, gains, K),\n",
    "                \"n_rel\":     len(rel_set)\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "id_to_idx = {hid: i for i, hid in enumerate(hotel_info[HOTEL_ID_COL].tolist())}\n",
    "frames = []\n",
    "frames.append(eval_method(\"tfidf\", COS_TFIDF))\n",
    "if COS_D2V is not None: frames.append(eval_method(\"doc2vec\", COS_D2V))\n",
    "if COS_SBERT is not None: frames.append(eval_method(\"sbert\", COS_SBERT))\n",
    "eval_df = pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()\n",
    "summary = (eval_df.groupby([\"method\",\"K\"])[[\"precision\",\"map\",\"ndcg_bin\",\"ndcg_grd\"]]\n",
    "           .mean().reset_index().sort_values([\"K\",\"method\"]))\n",
    "\n",
    "eval_df.to_csv(LOGS_DIR / f\"content_eval_results_{TS}.csv\", index=False)\n",
    "summary.to_csv(LOGS_DIR / f\"content_eval_summary_{TS}.csv\", index=False)\n",
    "display(summary)\n",
    "\n",
    "metrics = [\"precision\",\"map\",\"ndcg_bin\",\"ndcg_grd\"]\n",
    "saved_paths = []\n",
    "for m in metrics:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    for K in sorted(summary[\"K\"].unique()):\n",
    "        sub = summary[summary[\"K\"]==K]\n",
    "        x_labels = (sub[\"method\"] + \"_\" + sub[\"K\"].astype(str)).tolist()\n",
    "        plt.bar(x_labels, sub[m])\n",
    "    plt.title(f\"Mean {m} by method & K\")\n",
    "    plt.xlabel(\"method_K\")\n",
    "    plt.ylabel(m)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    out_png = PLOTS_DIR / f\"{m}.png\"\n",
    "    plt.savefig(out_png, dpi=150)\n",
    "    saved_paths.append(str(out_png))\n",
    "    plt.show()\n",
    "\n",
    "print(\"Saved charts:\", saved_paths)\n",
    "\n",
    "md_path = LOGS_DIR / f\"Agoda_RS_Report_{TS}.md\"\n",
    "try:\n",
    "    try:\n",
    "        tbl_md = summary.to_markdown(index=False)\n",
    "    except Exception:\n",
    "        tbl_md = summary.to_csv(index=False)\n",
    "\n",
    "    lines = []\n",
    "    lines.append(\"# Agoda Recommendation System — Report\\\\n\")\n",
    "    lines.append(f\"_Generated at: {TS}_\\\\n\")\n",
    "    lines.append(\"## Evaluation Results Summary\\\\n\")\n",
    "    lines.append(tbl_md + \"\\\\n\")\n",
    "    lines.append(\"## Charts\\\\n\")\n",
    "    for m in metrics:\n",
    "        img_rel = f\"plots/{m}.png\"\n",
    "        lines.append(f\"### {m}\\\\n\")\n",
    "        lines.append(f\"![{m}]({img_rel})\\\\n\")\n",
    "    with open(md_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\\\n\".join(lines))\n",
    "    print(\"Wrote Markdown report:\", md_path)\n",
    "except Exception as e:\n",
    "    print(\"Could not write Markdown:\", repr(e))\n",
    "\n",
    "pptx_path = LOGS_DIR / f\"Agoda_RS_Report_{TS}.pptx\"\n",
    "try:\n",
    "    from pptx import Presentation\n",
    "    from pptx.util import Inches, Pt\n",
    "    prs = Presentation()\n",
    "    slide = prs.slides.add_slide(prs.slide_layouts[0])\n",
    "    slide.shapes.title.text = \"Agoda Recommendation System — Report\"\n",
    "    subtitle = slide.placeholders[1]\n",
    "    subtitle.text = f\"Models & Evaluation Results Summary\\\\nGenerated at: {TS}\"\n",
    "\n",
    "    slide = prs.slides.add_slide(prs.slide_layouts[5])\n",
    "    slide.shapes.title.text = \"Metrics Summary (Average)\"\n",
    "    rows, cols = summary.shape[0] + 1, summary.shape[1]\n",
    "    table = slide.shapes.add_table(rows, cols, Inches(0.5), Inches(1.2), Inches(9), Inches(0.8 + 0.3*rows)).table\n",
    "    for j, col in enumerate(summary.columns):\n",
    "        table.cell(0, j).text = str(col)\n",
    "    for i in range(summary.shape[0]):\n",
    "        for j in range(cols):\n",
    "            table.cell(i+1, j).text = str(summary.iat[i, j])\n",
    "\n",
    "    for m in metrics:\n",
    "        img = PLOTS_DIR / f\"{m}.png\"\n",
    "        if img.exists():\n",
    "            slide = prs.slides.add_slide(prs.slide_layouts[5])\n",
    "            slide.shapes.title.text = f\"Charts: {m}\"\n",
    "            slide.shapes.add_picture(str(img), Inches(0.5), Inches(1.2), width=Inches(9))\n",
    "    prs.save(pptx_path)\n",
    "    print(\"Wrote PPTX report:\", pptx_path)\n",
    "except Exception as e:\n",
    "    print(\"Reason:\", repr(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226106fc",
   "metadata": {},
   "source": [
    "## 7. Generate Streamlit app (run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbdbf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "app_code = r'''\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "from pathlib import Path\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re, unicodedata\n",
    "\n",
    "DATA_DIR = Path(\"./data/\")\n",
    "p_info = DATA_DIR / \"hotel_info.csv\"\n",
    "p_comments = DATA_DIR / \"hotel_comments.csv\"\n",
    "\n",
    "OUTPUT_DIR = Path(\"./output/\")\n",
    "MODELS_DIR = OUTPUT_DIR / \"models\"\n",
    "\n",
    "def read_csv_safely(path, **kwargs):\n",
    "    for enc in [\"utf-8\", \"utf-8-sig\", \"cp1258\", \"latin-1\"]:\n",
    "        try:\n",
    "            return pd.read_csv(path, encoding=enc, **kwargs)\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "    raise last_err\n",
    "\n",
    "hotel_info = read_csv_safely(p_info)\n",
    "hotel_comments = read_csv_safely(p_comments)\n",
    "\n",
    "text_cols = [c for c in hotel_info.columns if re.search(r\"(Description)\", c, re.I)]\n",
    "id_cols   = [c for c in hotel_info.columns if re.search(r\"(Hotel_ID)\", c, re.I)]\n",
    "name_cols = [c for c in hotel_info.columns if re.search(r\"(Hotel_Name)\", c, re.I)]\n",
    "HOTEL_ID_COL   = id_cols[0] if id_cols else hotel_info.columns[0]\n",
    "HOTEL_NAME_COL = name_cols[0] if name_cols else (hotel_info.columns[1] if hotel_info.shape[1] > 1 else HOTEL_ID_COL)\n",
    "\n",
    "def simple_clean(s):\n",
    "    if not isinstance(s, str): s = str(s)\n",
    "    s = unicodedata.normalize(\"NFC\", s.lower())\n",
    "    s = re.sub(r\"http\\\\S+|www\\\\S+\", \" \", s)\n",
    "    s = re.sub(r\"[\\\\w.-]+@[\\\\w.-]+\", \" \", s)\n",
    "    s = re.sub(r\"\\\\d+\", \" \", s)\n",
    "    s = re.sub(r\"[^\\\\w\\\\sáàảãạăằắẳẵặâầấẩẫậéèẻẽẹêềếểễệíìỉĩịóòỏõọôồốổỗộơờớởỡợúùủũụưừứửữựýỳỷỹỵđ]\", \" \", s, flags=re.I)\n",
    "    s = re.sub(r\"\\\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "hotel_info[\"_text_info\"] = (hotel_info[text_cols].astype(str).agg(\" \".join, axis=1) if text_cols else \"\")\n",
    "corpus = hotel_info[\"_text_info\"].map(simple_clean).fillna(\"\")\n",
    "tfidf = TfidfVectorizer(max_features=40000, ngram_range=(1,2), min_df=2)\n",
    "X = tfidf.fit_transform(corpus)\n",
    "COS = cosine_similarity(X)\n",
    "\n",
    "st.set_page_config(page_title=\"Agoda RS Mini\", layout=\"wide\")\n",
    "st.title(\"Agoda Recommendation System\")\n",
    "\n",
    "method = st.sidebar.selectbox(\"Methods\", [\"TF-IDF\", \"Doc2Vec\", \"SBERT\", \"ALS\"])\n",
    "\n",
    "seed = st.selectbox(\"Choose Base Hotel:\", hotel_info[HOTEL_NAME_COL].astype(str).tolist())\n",
    "seed_id = hotel_info.loc[hotel_info[HOTEL_NAME_COL]==seed, HOTEL_ID_COL].iloc[0]\n",
    "idx = hotel_info.index[hotel_info[HOTEL_ID_COL]==seed_id][0]\n",
    "\n",
    "def show_recs(df):\n",
    "    st.write(df.reset_index(drop=True))\n",
    "\n",
    "if method == \"TF-IDF\":\n",
    "    sims = COS[idx]\n",
    "    top_idx = np.argsort(-sims)[:11]\n",
    "    out = hotel_info.iloc[top_idx][[HOTEL_ID_COL, HOTEL_NAME_COL]].copy()\n",
    "    out[\"similarity\"] = sims[top_idx]\n",
    "    out = out[out.index != idx].head(10)\n",
    "    show_recs(out)\n",
    "\n",
    "elif method == \"Doc2Vec\":\n",
    "    try:\n",
    "        D2V_EMB = np.load(MODELS_DIR / \"d2v_emb.npy\")\n",
    "        sims = cosine_similarity([D2V_EMB[idx]], D2V_EMB)[0]\n",
    "        top_idx = np.argsort(-sims)[:11]\n",
    "        out = hotel_info.iloc[top_idx][[HOTEL_ID_COL, HOTEL_NAME_COL]].copy()\n",
    "        out[\"similarity\"] = sims[top_idx]\n",
    "        out = out[out.index != idx].head(10)\n",
    "        show_recs(out)\n",
    "    except Exception as e:\n",
    "        st.warning(\"Doc2Vec embedding's not ready yet!!!\")\n",
    "\n",
    "elif method == \"SBERT\":\n",
    "    try:\n",
    "        SBERT_EMB = np.load(MODELS_DIR / \"sbert_emb.npy\")\n",
    "        sims = cosine_similarity([SBERT_EMB[idx]], SBERT_EMB)[0]\n",
    "        top_idx = np.argsort(-sims)[:11]\n",
    "        out = hotel_info.iloc[top_idx][[HOTEL_ID_COL, HOTEL_NAME_COL]].copy()\n",
    "        out[\"similarity\"] = sims[top_idx]\n",
    "        out = out[out.index != idx].head(10)\n",
    "        show_recs(out)\n",
    "    except Exception as e:\n",
    "        st.warning(\"SBERT embedding's not ready yet!!!.\")\n",
    "\n",
    "elif method == \"ALS\":\n",
    "    st.write(\"Input User ID for Suggestion:\")\n",
    "    user_id = st.number_input(\"User ID:\", min_value=0, step=1, value=0)\n",
    "    try:\n",
    "        import findspark\n",
    "        findspark.init()\n",
    "\n",
    "        from pyspark import SparkContext\n",
    "        from pyspark.ml.recommendation import ALSModel\n",
    "        from pyspark.sql import SparkSession\n",
    "        from pyspark.sql.functions import *\n",
    "\n",
    "        SparkContext.setSystemProperty('spark.hadoop.dfs.client.use.datanode.hostname', 'true')\n",
    "        sc = SparkContext(master=\"local\", appName=\"New Spark Context\")\n",
    "        sc.setLogLevel(\"ERROR\")\n",
    "\n",
    "\n",
    "        spark = SparkSession(sc)\n",
    "        spark\n",
    "\n",
    "        model_path = MODELS_DIR / \"best_als_model\"\n",
    "        model = ALSModel.load(str(model_path))\n",
    "        user_df = spark.createDataFrame([(user_id,)], [\"userId\"])\n",
    "        recs = model.recommendForUserSubset(user_df, 10).toPandas()\n",
    "        if recs.empty:\n",
    "            st.info(\"No suggestion for this User ID.\")\n",
    "        else:\n",
    "            rows = []\n",
    "            for arr in recs[\"recommendations\"].iloc[0]:\n",
    "                rows.append({\"itemId\": arr[\"itemId\"], \"score\": float(arr[\"rating\"])})\n",
    "            out = pd.DataFrame(rows)\n",
    "            try:\n",
    "                out = out.merge(hotel_info[[HOTEL_ID_COL, HOTEL_NAME_COL]].astype({HOTEL_ID_COL: out[\"itemId\"].dtype}), \n",
    "                                left_on=\"itemId\", right_on=HOTEL_ID_COL, how=\"left\")\n",
    "            except:\n",
    "                out = out.merge(hotel_info[[HOTEL_ID_COL, HOTEL_NAME_COL]], \n",
    "                                left_on=\"itemId\", right_on=HOTEL_ID_COL, how=\"left\")\n",
    "            show_recs(out)\n",
    "            spark.stop()\n",
    "            sc.stop()\n",
    "    except Exception as e:\n",
    "        spark.stop()\n",
    "        sc.stop()\n",
    "        st.warning(\"ALS model's not ready yet!!!.\")\n",
    "'''\n",
    "app_path = (Path(\"./app.py\"))\n",
    "app_path.write_text(app_code, encoding=\"utf-8\")\n",
    "print(\"Wrote app:\", app_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa01609",
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run ./app.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo_machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
